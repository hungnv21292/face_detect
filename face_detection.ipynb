{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model Haar-cascade Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"D:\\Master\\Thesis\\src\\opencv-master\\data\\haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier('D:\\Master\\Thesis\\src\\opencv-master\\data\\haarcascades\\haarcascade_eye.xml')\n",
    "\n",
    "# video_path = './../../data/video/ch3_26_3_1030_1130.mp4'\n",
    "\n",
    "# # load video\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcualte Background\n",
    "\n",
    "def getForeground(alpha, frame):\n",
    "    # Set background as first frame\n",
    "    backGroundModel = frame\n",
    "    # Update back ground model, apply the background averaging formula:\n",
    "    # NEW_BACKGROUND = CURRENT_FRAME * ALPHA + OLD_BACKGROUND * (1 - APLHA)\n",
    "    backGroundModel = frame * alpha + backGroundModel * (1- alpha)\n",
    "    \n",
    "    return cv2.absdiff(backGroundModel.astype(np.uint8), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray_pre = np.zeros((1080,1920),dtype=np.uint8)\n",
    "pre_face = 0\n",
    "\n",
    "frame_pos_list = []\n",
    "\n",
    "VIDEO_PATH = './../../data/video'\n",
    "RAW_IMG = './../../data/result/raw_img'\n",
    "DETECTED_IMG = './../../data/result/detected_img'\n",
    "FRAME_LIST = './../../data/result/frame_list'\n",
    "\n",
    "for root, dirs, files in os.walk(VIDEO_PATH):\n",
    "    files.sort()\n",
    "    \n",
    "    for idx, name in enumerate(files):\n",
    "        video_path = os.path.join(root, name)\n",
    "        video_name = name.split('.')[0]\n",
    "        \n",
    "        # Reset output dir\n",
    "        RAW_IMG_DIR = os.path.join(RAW_IMG, video_name)\n",
    "        if os.path.exists(RAW_IMG_DIR):\n",
    "            rmtree(RAW_IMG_DIR)\n",
    "        os.mkdir(RAW_IMG_DIR)\n",
    "        \n",
    "        DETECTED_IMG_DIR = os.path.join(DETECTED_IMG, video_name)\n",
    "        if os.path.exists(DETECTED_IMG_DIR):\n",
    "            rmtree(DETECTED_IMG_DIR)\n",
    "        os.mkdir(DETECTED_IMG_DIR)\n",
    "\n",
    "#         FRAME_LIST_DIR = os.path.join(FRAME_LIST, video_name)\n",
    "#         if os.path.exists(FRAME_LIST_DIR):\n",
    "#             rmtree(FRAME_LIST_DIR)\n",
    "#         os.mkdir(FRAME_LIST_DIR)\n",
    "        \n",
    "        # load video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            print ('frame nunber: %d' % cap.get(1))\n",
    "\n",
    "            if ret == True:\n",
    "\n",
    "                \"\"\"\n",
    "                # Method 1: Use createBackgroundSubtractorMOG2() function to calculate background.\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                fgmask = fgbg.apply(gray, learningRate=0.01)\n",
    "                fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "                ret, mask = cv2.threshold(fgmask, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                dif_rate = np.sum(mask)/(1080 * 1920)\n",
    "\n",
    "                if((dif_rate < 0.04) & (pre_face == 0)):\n",
    "                    continue\n",
    "\n",
    "                pre_face = 0\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                \"\"\"\n",
    "\n",
    "                #\"\"\"\n",
    "                # Method 2: Use subtract function in opencv\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                dif = cv2.subtract(gray, gray_pre)\n",
    "                th, dst = cv2.threshold(dif, 2, 1, cv2.THRESH_BINARY)\n",
    "                dif_rate = np.sum(dst) / (1080 * 1920)\n",
    "                gray_pre = gray\n",
    "\n",
    "                if((dif_rate < 0.04) & (pre_face == 0)):\n",
    "                    continue\n",
    "\n",
    "                pre_face = 0\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                #\"\"\"\n",
    "\n",
    "                \"\"\"\n",
    "                # Method 3: Use absDiff to calculate background model.\n",
    "                ###Get the foreground\n",
    "                foreGround = getForeground(0.01, frame)\n",
    "                foreGround = cv2.cvtColor(foreGround, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                #Apply thresholding on the background and display the resulting mask\n",
    "                ret, mask = cv2.threshold(foreGround, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                dif_rate = np.sum(mask)/(1080 * 1920)\n",
    "\n",
    "                if((dif_rate < 0.04) & (pre_face == 0)):\n",
    "                    continue\n",
    "\n",
    "                pre_face = 0\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                \"\"\"\n",
    "\n",
    "                if(len(faces) > 0):\n",
    "                    pre_face = 1\n",
    "\n",
    "                    frame_idx = cap.get(1)\n",
    "                    frame_pos_list.append(frame_idx)\n",
    "                    \n",
    "                    name_raw = os.path.join(RAW_IMG_DIR, 'frame%d' % frame_idx + '.png')\n",
    "                    #name_raw = './../../data/raw_img/'+ 'name' + 'frame%d' % frame_idx + '.png'\n",
    "                    \n",
    "                    cv2.imwrite(name_raw, frame)\n",
    "\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                        roi_gray = gray[y:y+h, x:x+w]\n",
    "                        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "                        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "                        for (ex, ey, ew, eh) in eyes:\n",
    "                           cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "                    # Save the detected image\n",
    "                    name_detected = os.path.join(DETECTED_IMG_DIR, 'frame%d' % frame_idx + '.png')\n",
    "                    cv2.imwrite(name_detected, frame)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "        # Save the frame list have face detect\n",
    "        frame_list_path = os.path.join(FRAME_LIST, video_name +  '.pkl')\n",
    "        with open(frame_list_path, 'wb') as f:\n",
    "            pickle.dump(frame_pos_list, f)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
