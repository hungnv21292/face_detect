{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model Haar-cascade Detection\n",
    "face_cascade = cv2.CascadeClassifier('../haarcascade_frontalface_default.xml')\n",
    "#eye_cascade = cv2.CascadeClassifier('D:\\Master\\Thesis\\src\\haarcascade_eye.xml')\n",
    "\n",
    "# video_path = './../../data/video/ch3_26_3_1130_1230.mp4'\n",
    "video_path = './../../data/video/output1.mp4'\n",
    "# video_path = './../../data/Target_and_Obstacle_Recognition.mp4'\n",
    "# load video\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcualte Background\n",
    "\n",
    "def getForeground(alpha, frame):\n",
    "    # Set background as first frame\n",
    "    backGroundModel = frame\n",
    "    # Update back ground model, apply the background averaging formula:\n",
    "    # NEW_BACKGROUND = CURRENT_FRAME * ALPHA + OLD_BACKGROUND * (1 - APLHA)\n",
    "    backGroundModel = frame * alpha + backGroundModel * (1- alpha)\n",
    "    \n",
    "    return cv2.absdiff(backGroundModel.astype(np.uint8), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame nunber: 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "D:\\Build\\OpenCV\\opencv-3.3.1\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215) !empty() in function cv::CascadeClassifier::detectMultiScale\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-757c26d0c6fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpre_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Get the foreground\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: D:\\Build\\OpenCV\\opencv-3.3.1\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215) !empty() in function cv::CascadeClassifier::detectMultiScale\n"
     ]
    }
   ],
   "source": [
    "gray_pre = np.zeros((1080,1920),dtype=np.uint8)\n",
    "pre_face = 0\n",
    "\n",
    "frame_pos_list = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    print ('frame nunber: %d' % cap.get(1))\n",
    "    #print (ret)\n",
    "    \n",
    "    if ret == True:\n",
    "        # Show image of video\n",
    "        #cv2.imshow('input', frame)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        dif = cv2.subtract(gray, gray_pre)\n",
    "        th, dst = cv2.threshold(dif, 2, 1, cv2.THRESH_BINARY)\n",
    "        dif_rate = np.sum(dst) / (1080 * 1920)\n",
    "        gray_pre = gray\n",
    "        \n",
    "        if((dif_rate < 0.04) & (pre_face == 0)):\n",
    "            continue\n",
    "        \n",
    "        pre_face = 0\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        # Get the foreground\n",
    "        #foreGround = getForeground(0.01, frame)\n",
    "        #foreGround = cv2.cvtColor(foreGround, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply thresholding on the background and display the resulting mask\n",
    "        #ret, mask = cv2.threshold(foreGround, 128, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "#         diff_rate = np.sum(mask)/(1080 * 1920)\n",
    "#         if(diff_rate < 0.05):\n",
    "#             continue\n",
    "            \n",
    "        print ('aaa')\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        if(len(faces) > 0):\n",
    "            pre_face = 1\n",
    "            \n",
    "            frame_idx = cap.get(cv2.CV_CAP_PROP_POS_FRAMES)\n",
    "            frame_pos_list.append(frame_idx)\n",
    "            \n",
    "            name_raw = './../../data/raw_img/' + 'frame%d' % frame_idx + '.png'\n",
    "            cv2.imwrite(name_raw, frame)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                cv.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                #eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "                #for (ex, ey, ew, eh) in eyes:\n",
    "                #    cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "                \n",
    "            # Save the detected image\n",
    "            name_detected = './../../data/detected_img/' + 'frame%d' % frame_idx + '.png'\n",
    "            cv2.imwrite(name_detected, frame)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "with open('Frame_detected_list.pkl', 'wb') as f:\n",
    "    pickle.dump(frame_pos_list, f)\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Microsoft API to detect face\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "import cognitive_face as CF\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"westcentralus\"\n",
    "subscription_key = \"d6ab8eba9c094e9592847e406db1a4fd\"\n",
    "assert subscription_key\n",
    "face_api_url = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect'\n",
    "\n",
    "headers = { 'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "\n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
